{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import asarray, load\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:  (6000, 128, 128, 4)\n",
      "Shape of label:  (6000, 2)\n"
     ]
    }
   ],
   "source": [
    "label = pd.read_csv('train_labels.csv', names=['sex', 'mood'])\n",
    "with load('train_data.npz') as f:\n",
    "    data = f['data']\n",
    "print('>> Shape of data: ', data.shape)\n",
    "print('>> Shape of label: ', label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilabel vectorizer\n",
    "label['combine'] = list(zip(label['sex'], label['mood']))\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "labels = label['combine'].unique()\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb = mlb.fit(labels)\n",
    "y = mlb.transform(label['combine']) #OHE multilabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Get Dataset\\n\\nimport requests\\ndef get_svg(sex, mood, seed):\\n    url = \\'https://avatars.dicebear.com/api/\\'+sex+\\'/\\'+seed+\\'.svg?mood[]=\\'+mood\\n    response = requests.get(url)\\n    filename = sex+\\'_\\'+mood+\\'_\\'+seed+\\'.svg\\'\\n    file1 = open(filename,\"w\") \\n    file1.write(response.content.decode(\\'utf-8\\'))\\n    file1.close()\\n    return url\\nfor sex in [\\'male\\', \\'female\\']:\\n    for mood in [\\'happy\\', \\'sad\\', \\'surprised\\']:\\n        for i in range(1000):\\n            get_svg(sex, mood, str(i))\\n            print(sex, mood, str(i))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Get Dataset\n",
    "\n",
    "import requests\n",
    "def get_svg(sex, mood, seed):\n",
    "    url = 'https://avatars.dicebear.com/api/'+sex+'/'+seed+'.svg?mood[]='+mood\n",
    "    response = requests.get(url)\n",
    "    filename = sex+'_'+mood+'_'+seed+'.svg'\n",
    "    file1 = open(filename,\"w\") \n",
    "    file1.write(response.content.decode('utf-8'))\n",
    "    file1.close()\n",
    "    return url\n",
    "for sex in ['male', 'female']:\n",
    "    for mood in ['happy', 'sad', 'surprised']:\n",
    "        for i in range(1000):\n",
    "            get_svg(sex, mood, str(i))\n",
    "            print(sex, mood, str(i))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Convert SVG to PNG\\n\\nimport os, sys\\nimport cairosvg\\npath = 'D:/DS/dicebear-avatar-multilabel/'\\nfor i in ['female_happy',\\n 'female_sad',\\n 'female_surprised',\\n 'male_happy',\\n 'male_sad',\\n 'male_surprised']:\\n    os.chdir(path+i)\\n    for file in os.listdir('.'):\\n        name = file.split('.svg')[0]\\n        cairosvg.svg2png(url=name+'.svg',\\n                 parent_width=128,\\n                 parent_height=128,\\n                 write_to=name+'.png') \\n\\nos.chdir(path)\\nos.listdir('.')\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Convert SVG to PNG\n",
    "\n",
    "import os, sys\n",
    "import cairosvg\n",
    "path = 'D:/DS/dicebear-avatar-multilabel/'\n",
    "for i in ['female_happy',\n",
    " 'female_sad',\n",
    " 'female_surprised',\n",
    " 'male_happy',\n",
    " 'male_sad',\n",
    " 'male_surprised']:\n",
    "    os.chdir(path+i)\n",
    "    for file in os.listdir('.'):\n",
    "        name = file.split('.svg')[0]\n",
    "        cairosvg.svg2png(url=name+'.svg',\n",
    "                 parent_width=128,\n",
    "                 parent_height=128,\n",
    "                 write_to=name+'.png') \n",
    "\n",
    "os.chdir(path)\n",
    "os.listdir('.')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Export training data to CSV\\nlst = []\\npath = 'D:/DS/dicebear-avatar-multilabel/'\\nfor i in ['female_happy',\\n 'female_sad',\\n 'female_surprised',\\n 'male_happy',\\n 'male_sad',\\n 'male_surprised']:\\n    os.chdir(path+i)\\n    for file in os.listdir('.'):\\n        if '.png' in file:\\n            image = Image.open(file)\\n            lst.append(asarray(image))\\nos.chdir(path)            \\nfrom numpy import savez_compressed\\nsavez_compressed('train_data.npz', data=lst)\\n\\nsex = ['female']*3000 + ['male']*3000\\nmood = ['happy']*1000 + ['sad']*1000 + ['surprised']*1000 + ['happy']*1000 + ['sad']*1000 + ['surprised']*1000\\npd.DataFrame(zip(sex, mood)).to_csv('train_labels.csv',header=None,index=None)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Export training data to CSV\n",
    "lst = []\n",
    "path = 'D:/DS/dicebear-avatar-multilabel/'\n",
    "for i in ['female_happy',\n",
    " 'female_sad',\n",
    " 'female_surprised',\n",
    " 'male_happy',\n",
    " 'male_sad',\n",
    " 'male_surprised']:\n",
    "    os.chdir(path+i)\n",
    "    for file in os.listdir('.'):\n",
    "        if '.png' in file:\n",
    "            image = Image.open(file)\n",
    "            lst.append(asarray(image))\n",
    "os.chdir(path)            \n",
    "from numpy import savez_compressed\n",
    "savez_compressed('train_data.npz', data=lst)\n",
    "\n",
    "sex = ['female']*3000 + ['male']*3000\n",
    "mood = ['happy']*1000 + ['sad']*1000 + ['surprised']*1000 + ['happy']*1000 + ['sad']*1000 + ['surprised']*1000\n",
    "pd.DataFrame(zip(sex, mood)).to_csv('train_labels.csv',header=None,index=None)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, finalAct=\"sigmoid\"):\n",
    "        model = tf.keras.Sequential(name='cnn_smallerVGGNet')\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\",\n",
    "                         input_shape=inputShape))\n",
    "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=chanDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=chanDim))\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=chanDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=chanDim))\n",
    "        model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=chanDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        \n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(1024))\n",
    "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        \n",
    "        # use a *softmax* activation for single-label classification\n",
    "        # and *sigmoid* activation for multi-label classification\n",
    "        model.add(tf.keras.layers.Dense(classes))\n",
    "        model.add(tf.keras.layers.Activation(finalAct))\n",
    "        \n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# initialize the number of epochs, initial learning rate, batch size, and image dimensions\n",
    "EPOCHS = 25\n",
    "INIT_LR = 1e-3\n",
    "BS = 50\n",
    "IMAGE_DIMS = (128, 128, 4)\n",
    "CLASSES = 5 # male, female, happy, surprised, sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_smallerVGGNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 32)      1184      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 42, 42, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 42, 42, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 42, 42, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 42, 42, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 21, 21, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1024)              13108224  \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5)                 5125      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 13,397,157\n",
      "Trainable params: 13,394,277\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SmallerVGGNet.build(\n",
    "    width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "    depth=IMAGE_DIMS[2], classes=CLASSES,\n",
    "    finalAct=\"sigmoid\")\n",
    "\n",
    "# initialize the optimizer\n",
    "opt = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('model.h5') == False:\n",
    "    # Set random seed for shuffling\n",
    "    np.random.seed(7)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(trainX, trainY, epochs=1, batch_size=BS, shuffle=True, verbose=1)\n",
    "\n",
    "    # Save model\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "        \n",
    "    # Save weights\n",
    "    model.save_weights(\"model.h5\")\n",
    "else:\n",
    "    # Load pre-trained weight\n",
    "    model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test):\n",
    "    probs = model.predict(tf.cast(test, tf.float32))\n",
    "    preds = []\n",
    "    for i in np.argsort(probs)[:,[-2,-1]]:\n",
    "        preds.append(set(mlb.classes_[i]))\n",
    "    return preds\n",
    "\n",
    "def accuracy(y_test, pred):\n",
    "    test = [set(i) for i in mlb.inverse_transform(y_test)]\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, j in zip(pred, test):\n",
    "        if i==j:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return float(correct)/float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = predict(model, testX)\n",
    "#accuracy(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female sad\n",
      "[{'female', 'sad'}]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAADBklEQVR4nO3dsWsUQRhA8T1RKwuLIJhOOAsTxcrO1lTbaWOnpBAhYEoRa+sIgigIdjbanU3yJ1hJ1MaDdAmIhaXYnIWVsjMwy3ezG9/7lctddkwew37Zjdc0kiRJklgmtU706cPuota5/geXr21U+dmcqHESjZcBwBkAnAHAGQCcAcCFjhqOenVEjojuAHAGAGcAcAYAZwBwva4mvdofpz7TgTsAnAHAGQCcAcAZAJwBwJ0cegEp6yu/hl5CFZ+/nx70/O4AcAYAZwBwBgBnAHDVpoDDo29Fr19fObuchQxkb/9H0etXz59bzkL+4Q4AZwBwBgBnAHAGABc6BeR+f3941H386Ys33cd7nH/27H6Pd5Vrt56Hfa0H9253Hs99LyPvH7gDwBkAnAHAGQCcAcAZAFyvMTA1omzv7CXfM5/PO4/PXj4sX8CpM52H27uPk2+ZTqdFp0itt2nqrPl9Zr072zfKz5/gDgBnAHAGAGcAcAYAF3ozKHd12m4lrqpXr3cefvTqdfJrPdm8U7CqP0qvnJPrbZoqa4680s9xB4AzADgDgDMAOAOAMwC40P8mrs/f9Ec+X3ccnwnsteafbefhyaXyn6c7AJwBwBkAnAHAGQDc4FOAyk0utH5kjGIYAJwBwBkAnAHAhT4Slvu7dSeEMpFX+jnuAHAGAGcAcAYAZwBwBgAXOmr0+UTRWuPh/u7Hotdf2bi6pJX8rda4l+IOAGcAcAYAZwBwBgAX+khYTuln2y8OZsXnGLOhr/ZT3AHgDADOAOAMAM4A4AwALvSZwNJRL6fP2LT4+rbK6Di5eGuUI10f7gBwBgBnAHAGAGcAcMkpIHfDJ/JqX8NyB4AzADgDgDMAOAOAq3Y1n/o9/eTLu+7Xr91c6npqK/131rrf4A4AZwBwBgBnAHAGAGcAcKGPhNV6JIsg972MHBHdAeAMAM4A4AwAzgDgQqeASKmbJ00z3htFuTWPlTsAnAHAGQCcAcAZAJwBwI12DMwZ+jnC4zjupbgDwBkAnAHAGQCcAcD9BgHYiOcMi6rpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=128x128 at 0x271D12B3160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cairosvg\n",
    "import requests\n",
    "import random\n",
    "\n",
    "def test(sex, mood, seed):\n",
    "    url = 'https://avatars.dicebear.com/api/'+sex+'/'+str(seed)+'.svg?mood[]='+mood\n",
    "\n",
    "    cairosvg.svg2png(bytestring=requests.get(url).content,\n",
    "                           parent_width=128,\n",
    "                           parent_height=128,\n",
    "                           write_to='test.png') \n",
    "    image = Image.open('test.png')\n",
    "    inp = np.reshape(asarray(image), (1,128,128,4))\n",
    "    print(sex, mood)\n",
    "    print(predict(model, asarray(inp)))\n",
    "    return image\n",
    "\n",
    "SEX = ['male', 'female']\n",
    "MOOD = ['sad', 'happy', 'surprised']\n",
    "\n",
    "test(sex=random.choice(SEX),\n",
    "     mood=random.choice(MOOD),\n",
    "     seed=random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gan_discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_15 (Flatten)         (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 512)               33554944  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 33,686,529\n",
      "Trainable params: 33,686,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"gan_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 65536)             67174400  \n",
      "_________________________________________________________________\n",
      "reshape_12 (Reshape)         (None, 128, 128, 4)       0         \n",
      "=================================================================\n",
      "Total params: 67,864,320\n",
      "Trainable params: 67,860,736\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class GAN():\n",
    "    def __init__ (self, width, height, depth):\n",
    "        # Init\n",
    "        self.inputShape = (height, width, depth)\n",
    "        self.latentDim = 100\n",
    "        optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        with open(\"gan_generator.json\", \"w\") as json_file:\n",
    "            json_file.write(self.generator.to_json()) \n",
    "        \n",
    "        z = tf.keras.Input(shape=(self.latentDim,))\n",
    "        img = self.generator(z)\n",
    "        validity = self.discriminator(img)\n",
    "        self.combined = tf.keras.Model(z, validity) # The combined adversarial model\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = tf.keras.Sequential(name='gan_generator')\n",
    "        model.add(tf.keras.layers.Dense(256, input_dim=self.latentDim))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "        model.add(tf.keras.layers.BatchNormalization(momentum=0.8))\n",
    "        model.add(tf.keras.layers.Dense(512))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "        model.add(tf.keras.layers.BatchNormalization(momentum=0.8))\n",
    "        model.add(tf.keras.layers.Dense(1024))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "        model.add(tf.keras.layers.BatchNormalization(momentum=0.8))\n",
    "        model.add(tf.keras.layers.Dense(np.prod(self.inputShape), activation='tanh'))\n",
    "        model.add(tf.keras.layers.Reshape(self.inputShape))\n",
    "        model.summary()\n",
    "        noise = tf.keras.Input(shape=(self.latentDim,))\n",
    "        img = model(noise)\n",
    "        return tf.keras.Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = tf.keras.Sequential(name='gan_discriminator')\n",
    "        model.add(tf.keras.layers.Flatten(input_shape=self.inputShape))\n",
    "        model.add(tf.keras.layers.Dense(512))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "        model.add(tf.keras.layers.Dense(256))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        img = tf.keras.Input(shape=self.inputShape)\n",
    "        validity = model(img)\n",
    "        return tf.keras.Model(img, validity)\n",
    "    \n",
    "    def train(self, X_train, epochs=EPOCHS, batch_size=BS, sample_interval=50):\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latentDim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch) # Print 25 images every sample interval\n",
    "                self.generator.save_weights(\"gan_generator.h5\") # Save updated weights every sample interval\n",
    "    \n",
    "    def generate(self, load_weight=True):\n",
    "        if load_weight:\n",
    "            self.generator.load_weights(\"gan_generator.h5\") # Load pre-trained weights\n",
    "        self.sample_images('final_model')\n",
    "    \n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latentDim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images_\"+str(epoch)+\".png\") # Save images\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.352376, acc.: 58.00%] [G loss: 1.088141]\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0], depth=IMAGE_DIMS[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan.train(X_train=data, epochs=1)\n",
    "#gan.generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
