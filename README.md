# The making of a Data Scientist

## Chapter XX. Things they did not teach at University

1. Parallel Processing with Apache Spark
- This is technically in the domain of Big Data Analytics, not purely ML
- Hadoop is the framework; Spark is the engine
- PySpark is the Python API for Spark
- Installation (as of May 2020) tutorial: https://medium.com/@naomi.fridman/install-pyspark-to-run-on-jupyter-notebook-on-windows-4ec2009de21f (3 things in the guide that beginners may want to Google cause it's a bit vague: 1) Change system PATH & ENV 2) Don't download the most up-to-date version of Java, download the **Java 8** from the link in the article - note that you need to sign up an Oracle account for this 3) Download & install **7.ZIP** in order to extract the .gz file from Apache Spark)

